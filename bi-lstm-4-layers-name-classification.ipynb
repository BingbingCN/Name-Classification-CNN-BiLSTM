{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from io import open\nimport glob\nimport os\ndef findFiles(path): return glob.glob(path)\nfindFiles('../input/multilingual-names/*.txt')","metadata":{"execution":{"iopub.status.busy":"2022-07-09T10:56:11.752905Z","iopub.execute_input":"2022-07-09T10:56:11.754162Z","iopub.status.idle":"2022-07-09T10:56:11.798421Z","shell.execute_reply.started":"2022-07-09T10:56:11.753987Z","shell.execute_reply":"2022-07-09T10:56:11.797288Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import unicodedata\nimport string\nall_letters = string.ascii_letters + \" .,;'\"\nn_letters = len(all_letters)\n# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n        and c in all_letters\n    )\nunicodeToAscii('Ślusàrski')","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:11.801328Z","iopub.execute_input":"2022-07-09T10:56:11.802241Z","iopub.status.idle":"2022-07-09T10:56:11.816355Z","shell.execute_reply.started":"2022-07-09T10:56:11.802198Z","shell.execute_reply":"2022-07-09T10:56:11.814803Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Build the category_lines dictionary, a list of names per language\ncategory_lines = {}\nall_categories = []\n\n# Read a file and split into lines\ndef readLines(filename):\n    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n    return [unicodeToAscii(line) for line in lines]\n\nfor filename in findFiles('../input/multilingual-names/*.txt'):\n    category = os.path.splitext(os.path.basename(filename))[0]\n    all_categories.append(category)\n    lines = readLines(filename)\n    category_lines[category] = lines\n\nn_categories = len(all_categories)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:11.902423Z","iopub.execute_input":"2022-07-09T10:56:11.903902Z","iopub.status.idle":"2022-07-09T10:56:12.077589Z","shell.execute_reply.started":"2022-07-09T10:56:11.903857Z","shell.execute_reply":"2022-07-09T10:56:12.076185Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"category_lines['Chinese'][:5]","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:12.081483Z","iopub.execute_input":"2022-07-09T10:56:12.082369Z","iopub.status.idle":"2022-07-09T10:56:12.092833Z","shell.execute_reply.started":"2022-07-09T10:56:12.082328Z","shell.execute_reply":"2022-07-09T10:56:12.091170Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def split_line(name:str):\n    return list(name)\n\nsplit_line(\"Slusarski\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:12.095034Z","iopub.execute_input":"2022-07-09T10:56:12.096400Z","iopub.status.idle":"2022-07-09T10:56:12.111034Z","shell.execute_reply.started":"2022-07-09T10:56:12.096358Z","shell.execute_reply":"2022-07-09T10:56:12.109456Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_pairs = []\nfor category_name, lines in category_lines.items():\n    for name in lines:\n        data_pairs.append((split_line(name), category_name))\n\ndata_pairs[:5]","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:12.112795Z","iopub.execute_input":"2022-07-09T10:56:12.113868Z","iopub.status.idle":"2022-07-09T10:56:12.233750Z","shell.execute_reply.started":"2022-07-09T10:56:12.113822Z","shell.execute_reply":"2022-07-09T10:56:12.232377Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.seed(114514)\n\nindex = list(range(len(data_pairs)))\n\nrandom.shuffle(index)\n\nvalid_index = index[:2000]\ntest_index = index[2000:4000]\ntrain_index = index[4000:]\n\nvalid_pairs = [data_pairs[i] for i in valid_index]\ntest_pairs = [data_pairs[i] for i in test_index]\ntrain_pairs = [data_pairs[i] for i in train_index]\n\nvalid_pairs[:5]","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:12.238273Z","iopub.execute_input":"2022-07-09T10:56:12.238583Z","iopub.status.idle":"2022-07-09T10:56:12.278026Z","shell.execute_reply.started":"2022-07-09T10:56:12.238554Z","shell.execute_reply":"2022-07-09T10:56:12.276659Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class WordDict:\n    def __init__(self) -> None:\n        self.index2word = {}\n        self.word2index = {}\n        self.dict_size = 0\n    def add_word(self, word:str):\n        if word not in self.word2index:\n            self.word2index[word] = self.dict_size\n            self.index2word[self.dict_size] = word\n            self.dict_size += 1\n    def index(self, word:str):\n        if word in self.word2index:\n            return self.word2index[word]\n        else:\n            return -1\n    def word(self, index:int):\n        if index in self.index2word:\n            return self.index2word[index]\n        else:\n            return \"<unk>\"\nname_dict = WordDict()\ncategory_dict = WordDict()\n\nname_dict.add_word(\"<pad>\")\nfor name, category_name in data_pairs:\n    for char in name:\n        name_dict.add_word(char)\n    category_dict.add_word(category_name)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:12.282049Z","iopub.execute_input":"2022-07-09T10:56:12.282910Z","iopub.status.idle":"2022-07-09T10:56:12.340072Z","shell.execute_reply.started":"2022-07-09T10:56:12.282867Z","shell.execute_reply":"2022-07-09T10:56:12.338780Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom typing import Tuple, List\n\nclass NameDataset(Dataset):\n    def __init__(self, pairs:Tuple[List[str], str], name_dict:WordDict, category_dict:WordDict) -> None:\n        super().__init__()\n        self.pairs = pairs\n        self.name_dict = name_dict\n        self.category_dict = category_dict\n\n    def __getitem__(self, index):\n        name, category = self.pairs[index]\n        x = torch.LongTensor([self.name_dict.index(char) for char in name])\n        y = torch.LongTensor([self.category_dict.index(category)])\n        return (x,y)\n\n    def __len__(self):\n        return len(self.pairs)\nvalid_dataset = NameDataset(valid_pairs, name_dict, category_dict)\ntest_dataset = NameDataset(test_pairs, name_dict, category_dict)\ntrain_dataset = NameDataset(train_pairs, name_dict, category_dict)\n\nvalid_dataset[5]","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:12.341624Z","iopub.execute_input":"2022-07-09T10:56:12.342666Z","iopub.status.idle":"2022-07-09T10:56:14.451954Z","shell.execute_reply.started":"2022-07-09T10:56:12.342573Z","shell.execute_reply":"2022-07-09T10:56:14.450754Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#由于不同的姓名长度不统一，下面定义一个函数填充长度不足的词组\ndef collate_fn(pair_list):\n    input_list, label_list = zip(*pair_list)\n\n    max_len = max([len(input_tensor) for input_tensor in input_list])\n\n    collated_input = []\n    for input_tensor in input_list:\n        padding_len = max_len - len(input_tensor)\n        padding_tensor = torch.zeros((padding_len,), dtype=torch.long)\n        padding_tensor[:] = name_dict.index(\"<pad>\")\n        collated_input.append(torch.cat([padding_tensor,input_tensor], dim=0))\n\n    collated_input = torch.stack(collated_input, dim=0)\n    collated_label = torch.cat(label_list, dim=0)\n    return collated_input, collated_label","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:14.454212Z","iopub.execute_input":"2022-07-09T10:56:14.454855Z","iopub.status.idle":"2022-07-09T10:56:14.464249Z","shell.execute_reply.started":"2022-07-09T10:56:14.454810Z","shell.execute_reply":"2022-07-09T10:56:14.462962Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nvalid_dataloader = DataLoader(valid_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\nfor data,label in valid_dataloader:\n    print(data)\n    print(label)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:14.466676Z","iopub.execute_input":"2022-07-09T10:56:14.467788Z","iopub.status.idle":"2022-07-09T10:56:14.700161Z","shell.execute_reply.started":"2022-07-09T10:56:14.467741Z","shell.execute_reply":"2022-07-09T10:56:14.698808Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for batch in valid_dataloader:\n    print(batch[0][:4])\n    print(batch[1][:4])\n    break","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:14.701435Z","iopub.execute_input":"2022-07-09T10:56:14.702832Z","iopub.status.idle":"2022-07-09T10:56:14.740624Z","shell.execute_reply.started":"2022-07-09T10:56:14.702788Z","shell.execute_reply":"2022-07-09T10:56:14.739050Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T10:56:14.743622Z","iopub.execute_input":"2022-07-09T10:56:14.744551Z","iopub.status.idle":"2022-07-09T10:56:14.833800Z","shell.execute_reply.started":"2022-07-09T10:56:14.744498Z","shell.execute_reply":"2022-07-09T10:56:14.832168Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"drop_out=0.1\nbatch_size=512\n# dataloader\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn) # shuffle=True打乱采样顺序（随机抽取Batch）\nloss_func = nn.CrossEntropyLoss(reduction = \"sum\").to(device) # 先把每个Batch的loss加起来不平均\n# [len(data[0])]*128","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T11:28:01.088269Z","iopub.execute_input":"2022-07-09T11:28:01.088950Z","iopub.status.idle":"2022-07-09T11:28:01.098797Z","shell.execute_reply.started":"2022-07-09T11:28:01.088916Z","shell.execute_reply":"2022-07-09T11:28:01.097199Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epoch_n = 100\n# for i in range(epoch_n):\n#     print(f'Epoch: {i+1:02} ')\n#     train(model, optimizer, loss_func, train_dataloader)\n#     evaluate(model, valid_dataloader)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T11:14:07.093139Z","iopub.execute_input":"2022-07-09T11:14:07.093555Z","iopub.status.idle":"2022-07-09T11:14:07.099402Z","shell.execute_reply.started":"2022-07-09T11:14:07.093529Z","shell.execute_reply":"2022-07-09T11:14:07.097740Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self,vocab_size,embedding_dim,hidden_dim,out_dim,bidirectional,dropout):\n        super().__init__()\n        self.embedding=nn.Embedding(vocab_size,embedding_dim)\n        self.rnn=nn.LSTM(embedding_dim,hidden_dim,num_layers=4,bidirectional=bidirectional,dropout=dropout,batch_first=True)\n        self.fc=nn.Linear(hidden_dim*4,out_dim)\n        self.dropout=nn.Dropout(dropout)\n    def forward(self,text):\n        embedded=self.dropout(self.embedding(text))\n        #packed_embedded=nn.utils.rnn.pack_padded_sequence(embedded,text_lengths)\n        packed_out,(hidden,cell)=self.rnn(embedded)\n        hidden=self.dropout(torch.cat((hidden[-4,:,:],hidden[-3,:,:],hidden[-2,:,:],hidden[-1,:,:]),dim=1))\n        return self.fc(hidden)\nmodel2=RNN(vocab_size=name_dict.dict_size,embedding_dim=64,hidden_dim=128,out_dim=category_dict.dict_size,dropout=drop_out,bidirectional=True)\nmodel2=model2.to(device)\noptimizer=torch.optim.Adam(params=model2.parameters())","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T11:14:07.102360Z","iopub.execute_input":"2022-07-09T11:14:07.103251Z","iopub.status.idle":"2022-07-09T11:14:07.138712Z","shell.execute_reply.started":"2022-07-09T11:14:07.103194Z","shell.execute_reply":"2022-07-09T11:14:07.137585Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model2):,} trainable parameters')\ncount_parameters(model2)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T11:14:07.141236Z","iopub.execute_input":"2022-07-09T11:14:07.141940Z","iopub.status.idle":"2022-07-09T11:14:07.153741Z","shell.execute_reply.started":"2022-07-09T11:14:07.141897Z","shell.execute_reply":"2022-07-09T11:14:07.152117Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def train_RNN(model:nn.Module, optimizer:torch.optim.Optimizer, loss_func, dataloader):\n    sum_loss = 0\n    train_num = 0\n    loss_list=[]\n    counter=0\n    model.train() # 将model设置为训练状态\n    for input_data, label in dataloader:\n        counter=counter+1\n        optimizer.zero_grad() # 初始化梯度\n\n        pred = model(input_data.to(device))\n        loss:Tensor = loss_func(pred, label.to(device))\n        if(counter%10==0):\n            loss_list.append(loss.item())\n        sum_loss += loss.detach()\n        train_num += len(input_data)\n        # 对loss求导数\n        loss.backward()\n        optimizer.step() # 更新参数\n    print(f\"\\tAvg loss:{(sum_loss/train_num).item()}\")\n    return loss_list\ndef evaluate_RNN(model:nn.Module, dataloader):\n    acc_num = 0\n    all_num = 0\n    model.eval() # 将model设置为评估状态\n    for input_data, label in dataloader:\n        # text_lengths=[len(input_data[0])]*batch_size\n        pred = model(input_data.to(device))\n        acc_num += (pred.max(dim=1)[1] == label.to(device)).sum().item()\n        all_num += len(input_data)\n    print(f\"\\tacc rate: {acc_num/all_num}\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T11:14:07.155776Z","iopub.execute_input":"2022-07-09T11:14:07.156975Z","iopub.status.idle":"2022-07-09T11:14:07.169971Z","shell.execute_reply.started":"2022-07-09T11:14:07.156854Z","shell.execute_reply":"2022-07-09T11:14:07.168645Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"total_loss_list=[]\nfor i in range(20):\n    print(f'Epoch: {i+1:02} ')\n    each_loss=train_RNN(model2, optimizer, loss_func, train_dataloader)\n    total_loss_list=total_loss_list+each_loss\n    evaluate_RNN(model2, valid_dataloader)\n\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n","is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-09T11:14:07.173661Z","iopub.execute_input":"2022-07-09T11:14:07.175397Z","iopub.status.idle":"2022-07-09T11:16:34.287978Z","shell.execute_reply.started":"2022-07-09T11:14:07.175356Z","shell.execute_reply":"2022-07-09T11:16:34.286575Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\ndef plot_progress(progress):\n        df = pd.DataFrame(progress, columns=['loss'])\n        df.plot(ylim=(0), figsize=(16,8), alpha=0.4, marker='.', grid=True)\n        plt.title('Loss Changes')\nplot_progress(total_loss_list)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-09T11:16:34.290443Z","iopub.execute_input":"2022-07-09T11:16:34.291351Z","iopub.status.idle":"2022-07-09T11:16:34.563353Z","shell.execute_reply.started":"2022-07-09T11:16:34.291306Z","shell.execute_reply":"2022-07-09T11:16:34.562159Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"em_dim=[32,64,128,256]\nhi_dim=[32,64,128,256]\ndef crazy_train(em_dim_list,hi_dim_list):\n    loss_list=[]\n    for i in em_dim_list:\n        for j in hi_dim_list:\n            model2=RNN(vocab_size=name_dict.dict_size,embedding_dim=i,hidden_dim=j,out_dim=category_dict.dict_size,dropout=drop_out,bidirectional=True)\n            model2=model2.to(device)\n            optimizer=torch.optim.Adam(params=model2.parameters())\n            total_loss_list=[]\n            for i in range(20):\n                print(f'Epoch: {i+1:02} ')\n                each_loss=train_RNN(model2, optimizer, loss_func, train_dataloader)\n                total_loss_list=total_loss_list+each_loss\n                evaluate_RNN(model2, valid_dataloader)\n            loss_list.append(total_loss_list)\n    return loss_list\nloss_list=crazy_train(em_dim,hi_dim)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T11:45:01.795671Z","iopub.execute_input":"2022-07-09T11:45:01.796063Z","iopub.status.idle":"2022-07-09T11:55:20.535686Z","shell.execute_reply.started":"2022-07-09T11:45:01.796033Z","shell.execute_reply":"2022-07-09T11:55:20.534170Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['font.family'] = 'serif'\nplt.figure(figsize=(16,10),dpi=400)\nplt.plot(range(len(loss_list[0])),loss_list[0],label='Embedding dim=32,Hidden dim=32')\nplt.plot(range(len(loss_list[1])),loss_list[1],label='Embedding dim=32,Hidden dim=64')\nplt.plot(range(len(loss_list[2])),loss_list[2],label='Embedding dim=32,Hidden dim=128')\nplt.plot(range(len(loss_list[3])),loss_list[3],label='Embedding dim=32,Hidden dim=256')\nplt.plot(range(len(loss_list[0])),loss_list[4],label='Embedding dim=64,Hidden dim=32')\nplt.plot(range(len(loss_list[1])),loss_list[5],label='Embedding dim=64,Hidden dim=64')\nplt.plot(range(len(loss_list[2])),loss_list[6],label='Embedding dim=64,Hidden dim=128')\nplt.plot(range(len(loss_list[3])),loss_list[7],label='Embedding dim=64,Hidden dim=256')\nplt.plot(range(len(loss_list[0])),loss_list[8],label='Embedding dim=128,Hidden dim=32')\nplt.plot(range(len(loss_list[1])),loss_list[9],label='Embedding dim=128,Hidden dim=64')\nplt.plot(range(len(loss_list[2])),loss_list[10],label='Embedding dim=128,Hidden dim=128')\nplt.plot(range(len(loss_list[3])),loss_list[11],label='Embedding dim=128,Hidden dim=256')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T12:13:33.494148Z","iopub.execute_input":"2022-07-09T12:13:33.494622Z","iopub.status.idle":"2022-07-09T12:13:35.089585Z","shell.execute_reply.started":"2022-07-09T12:13:33.494577Z","shell.execute_reply":"2022-07-09T12:13:35.087171Z"},"trusted":true},"execution_count":52,"outputs":[]}]}